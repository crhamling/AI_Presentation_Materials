{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Number 2 Submission - Investigate a Dataset - Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Titanic](titanic.png \"Titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  \n",
    "\n",
    "**SUBMISSION AGENDA for the Question: **  - **\"What factors made people more likely to survive?\"**\n",
    "\n",
    "\n",
    "**(A) Initial Dataset Interrogation** - A cursory investigation of what is known about the dataset and it's contents.\n",
    "\n",
    "\n",
    "**(B) Direction of Inquiry** - An overview of the facts generally known about the event, it's relevant history and the culture of the time period, a perusal of publicly available data gathered in the wake of the tragedy, and an attempt to make a case for the initial (and subsequent) line(s) of inquiry one might make of the dataset.\n",
    "\n",
    "\n",
    "**(C) Data Analysis and Discovery:** \n",
    "1. Perform exploratory analysis on dataset to get acquainted with the data \n",
    "2. Establish major contributing factors governing survival rates \n",
    "3. Construct basic heuristics to predict survival rates and a methodology to assess it's accuracy \n",
    "4. Incorporate machine learning to verify findings, enhance accuracy, and suggest additional causal factors\n",
    "5. Illuminate the necessary dataset transformations required for advanced feature modeling \n",
    "6. Engage in feature engineering to further uncover key contributory features\n",
    "7. Construct an advanced heuristic to better predict survival rates\n",
    "\n",
    "\n",
    "**(D) FINDINGS / CONCLUSIONS REPORT** - A summary of the findings are presented along with inferences and supporting data.\n",
    "\n",
    "**(E) LIMITATIONS and SHORTCOMINGS** -  A summary the limitations and shortcomings regardings the results and the methods being used.\n",
    "\n",
    "**(F) REFERENCES**\n",
    "\n",
    "\n",
    ">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandasql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4aa066d1ad50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandasql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandasql'"
     ]
    }
   ],
   "source": [
    "# Setup the various IMPORT statements for required libraries\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from __future__ import division  # forces \"/ \"to adopt Python 3.x's behavior that always returns a float.\n",
    "\n",
    "# Ignore Deprecation Warnings \n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "# Inline Graphics for IPython NB's\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW OF THE DATASET: ** \n",
    "\n",
    "> This is a quick perusal of the datset to understand it's structure, features distribution, missing values (and how they are handled), and general information about the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the Titanic Dataset into a Pandas DataFrame\n",
    "filename = 'titanic_data.csv'\n",
    "titanic_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a cursory examination of the data by listing the first 10 lines of the dataframe.\n",
    "titanic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick glance at the structure of the data. \n",
    "# It is obvious that there exists some missing data for Age (714) and Cabin (204). \n",
    "# Age is important so the NAN's will be substituted with the Median Age.\n",
    "# Cabin can safely be ignored since it's not used in the analysis.\n",
    "\n",
    "# NOTE: Later during the Machine Learning Phase, the variable AGE will need to be handled\n",
    "#       appropriately along with SEX and EMBARKED (which will need to be transformed into \n",
    "#       numerical values rather than strings).\n",
    "\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A) INITIAL DATASET INTERROGATION**\n",
    "\n",
    "> A cursory investigation of what is known about the dataset and it's structure.\n",
    "\n",
    "Each **row** (of the 891 total records) represents a single passenger on the titanic:\n",
    "\n",
    "* PassengerId -- A numerical id assigned to each passenger.\n",
    "* Survived -- Whether the passenger survived (1), or perished (0).\n",
    "* Pclass -- The class the passenger was in -- first class (1), second class (2), or third class (3).\n",
    "* Name -- the name of the passenger.\n",
    "* Sex -- The gender of the passenger -- male or female.\n",
    "* Age -- The age of the passenger.\n",
    "* SibSp -- The number of siblings and spouses the passenger had on board.\n",
    "* Parch -- The number of parents and children the passenger had on board.\n",
    "* Ticket -- The ticket number of the passenger.\n",
    "* Fare -- How much the passenger paid for the ticker.\n",
    "* Cabin -- Which cabin the passenger was in.\n",
    "* Embarked -- Port of Embarkation: (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "**Special Notes:**\n",
    "Pclass is a proxy for **socio-economic status** (SES): 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "> With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "* Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "* Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "* Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "* Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "\n",
    "* Source: https://www.kaggle.com/c/titanic/data\n",
    "\n",
    ">  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Rates via Gender and Class \n",
    "# This shows that women survived most, as well as those in 1st and 2nd class.\n",
    "\n",
    "pclass_plt = sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=titanic_df)\n",
    "pclass_plt.set_title('Survival Rates for Class and Gender')\n",
    "pclass_plt.set_ylabel('Survival')\n",
    "pclass_plt.set_xlabel('Class & Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Rates via Siblings and Class \n",
    "#\n",
    "# This is interesting in that larger families tended to perished whole,\n",
    "# while those with only one child (perhaps to carry the family name) \n",
    "# or infant was favored.\n",
    "\n",
    "sib_survived_plt = sns.pointplot(x=\"SibSp\", y=\"Survived\", hue=\"Pclass\", data=titanic_df)\n",
    "sib_survived_plt.set_title('Survival Rates for Class and # of Siblings')\n",
    "sib_survived_plt.set_ylabel('Survived')\n",
    "sib_survived_plt.set_xlabel('Number of siblings ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Rates via port of departure\n",
    "#\n",
    "# The data suggests that \"C\" - Embarked at Cherbourg stood a higher chance of survival.\n",
    "\n",
    "embarked_plt = sns.barplot(x=\"Embarked\", y=\"Survived\", data=titanic_df)\n",
    "embarked_plt.set_title('Survival Rates for Port of Departure')\n",
    "embarked_plt.set_ylabel('Survived')\n",
    "embarked_plt.set_xlabel('Port of Embarkment ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASSENGER AGE\n",
    "# Standard Normal Distribution of a quantative variable with a Large Mean and a few outliers.\n",
    "\n",
    "# Data Transformation - Drop the NAN's \n",
    "age_no_nans = titanic_df[\"Age\"].dropna()\n",
    "\n",
    "age_plt = sns.distplot(age_no_nans, kde=False)\n",
    "age_plt.set_title('Passenger Age Distribution')\n",
    "age_plt.set_ylabel('Frequency')\n",
    "age_plt.set_xlabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET PRICE: Fare\n",
    "# The majority of the tickets were of the cheaper variety (likely 3rd Class)\n",
    "# There were far less of the \"more\" expensive tickets: (1st and 2nd Class)\n",
    "\n",
    "fare_plt = sns.distplot(titanic_df.Fare, kde=False)\n",
    "fare_plt.set_title('Ticket Price Distribution')\n",
    "fare_plt.set_ylabel('Frequency')\n",
    "fare_plt.set_xlabel('Ticket Fare Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICATION: Confirm the record count in the Dataset is actually 891.\n",
    "len(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(B) DIRECTION OF INQUIRY - The Question(s) to be Answered. **\n",
    "\n",
    "> An overview of the facts generally known about the event, it's history and the culture of the time period, a perusal of publically available data gathered in the wake of the tragedy, and an attempt to make a case for the initial (and subsequent) line(s) of inquiry that might make of the dataset.\n",
    "\n",
    "\n",
    "**Generally Available Information** - to establish **general trends** and avenues of inquiry only, *not* necessarily specific to the dataset to be interrogated:\n",
    "\n",
    "* **Fewer than a third** of those aboard Titanic **survived** the disaster.\n",
    "* Titanic's passengers numbered **roughly** around 1,317 people: 324 in **First Class**, 284 in **Second Class**, and 709 in **Third Class**. \n",
    "* Of these, 869 (66%) were **male** and 447 (34%) **female**. There were 107 **children** aboard, the **largest number** of which were in **Third Class**.\n",
    "* The ship was considerably **under capacity** on her maiden voyage, as she **could** accommodate 2,566 passengers—1,034 First Class, 510 Second Class, and **1,022** in Third Class.\n",
    "\n",
    "\n",
    "* Source: https://en.wikipedia.org/wiki/RMS_Titanic\n",
    "\n",
    "\n",
    "> \n",
    "\n",
    "**Dataset Specific Information** - pertaining to **this** analysis specifically:\n",
    "\n",
    "\n",
    "* The dataset examined in this study is considerably **smaller** and only contains passenger information from a total of ** 891** of the total number of passengers on board the Titanic.\n",
    "\n",
    "> \n",
    "\n",
    "**Event History and Time Period Cultural Considerations:** \n",
    "\n",
    "> The time period of the event was the early 1900's, specifically **1912**. That was a time where **Chivalry** was very much alive and well as evidenced by the account of the **ships eight-member band**, led by Wallace Hartley. They had assembled in the first-class lounge in an effort to **keep passengers calm and upbeat**. Later they moved on to the forward half of the boat deck. The band continued playing, even when it became apparent the ship was going to sink, and that all members would perish.\n",
    "\n",
    "* Source: https://en.wikipedia.org/wiki/Legends_and_myths_regarding_RMS_Titanic\n",
    "\n",
    "> To emphasize the gravity of the cultural imperative of **Chivalry** prevalent during that that time period, it is useful to contrast that event against a more recent example of **Cowardice** in a similar event, namely **The Costa Concordia** where the disgraced ships captain Francesco Schettino (discovered to be chiefly responsible for the disaster), fled in a lifeboat while there were **still** passengers attempting to escape the doomed ship.\n",
    "\n",
    "* Source(s): \n",
    "    + http://www.reddirtreport.com/dust-devil-dreams/1912-chivalry-vs-2012-cowardice\n",
    "    + http://blogs.wsj.com/speakeasy/2012/01/23/the-costa-concordia-the-titanic-and-cowardice-at-sea/\n",
    "\n",
    "\n",
    "> \n",
    "\n",
    "\n",
    "**The Case for an Initial Line of Inquiry:** \n",
    "\n",
    "> Given the evidence (and gravity) of **Chivalry** during that time period, it is **reasonable** to expect that phenomenon would be **heavily manifested** in the factors indigenous to the survival demographics of the disaster. More specifically the overarching philosophy that **\"Women and Children First\"** should be significantly represented in the data.\n",
    "\n",
    "\n",
    "\n",
    "That will be the **first line of investigation** for this dataset.\n",
    "\n",
    "**Key Question: ** Did \"Women and Children\" survive in the numbers we would expect given the cultural imperative of the time period?\n",
    "\n",
    ">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**First line of investigation: **  - \"Women and Children First\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate the survived vs perished vs total sums given a pandas series.\n",
    "# Ingests a Pandas DataFrame and tally a count of those who lived and perished.\n",
    "# Returns lived, died, total\n",
    "\n",
    "def mortality_summary(dataframe):\n",
    "    lived = dataframe[dataframe['Survived']== 1]['PassengerId'].count()\n",
    "    died = dataframe[dataframe['Survived']== 0]['PassengerId'].count()\n",
    "    return lived, died, lived + died\n",
    "\n",
    "# Isolate those who survived and those who perished given a pandas dataframe\n",
    "# Ingests a dataframe and leverage the \"pandasql\" framework to select only those whom\n",
    "# survived and then only those whom perished, and then count them.\n",
    "# Returns survived, perished\n",
    "\n",
    "def isolate_survived_perished(dataframe):\n",
    "    select_perished = \"\"\"SELECT COUNT(PassengerId) FROM dataframe where Survived == 0;\"\"\"\n",
    "    select_survived = \"\"\"SELECT COUNT(PassengerId) FROM dataframe where Survived == 1;\"\"\"\n",
    "    perished = pandasql.sqldf(select_perished, locals())\n",
    "    survived = pandasql.sqldf(select_survived, locals())\n",
    "    return survived, perished\n",
    "\n",
    "# Function to count males vs females for the event in question (survived = 1 or perished = 0)\n",
    "# Ingests a Pandas dataframe and counts the number of males vs females \n",
    "# Returns the count of each.\n",
    " \n",
    "def males_vs_females(dataframe, survived):\n",
    "    males = dataframe[(dataframe['Survived']== survived) & (dataframe['Sex']== 'male')]['PassengerId'].count()\n",
    "    females = dataframe[(dataframe['Survived']== survived)  & (dataframe['Sex']== 'female')]['PassengerId'].count()\n",
    "    \n",
    "    return males, females\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALCULATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the overall total of how many lived, died, and sum for the total\n",
    "# lived, died, total = mortality_summary(titanic_df['Survived'])\n",
    "lived, died, total = mortality_summary(titanic_df)\n",
    "print (\"OVERALL TALLY's - LIVED: \", lived, \"DIED: \", died, \"TOTAL: \", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the counts for survived and perished given a pandas dataframe\n",
    "survived, perished = isolate_survived_perished(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICATION: check that the isolated counts match with the overall counts from the dataframe using a different \n",
    "# method of calculation.\n",
    "print (\"SURVIVED: \", survived) \n",
    "print(\"\\n\")\n",
    "print (\"PERISHED: \", perished)\n",
    "\n",
    "# NOTICE: Tests verify that counts match up as expected with the dataframe - SURVIVED:  342 PERISHED:  549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Investigation Inflection Point: **  \n",
    "\n",
    ">  Compare how many males vs females \"survived\", and subsequently count how many \"perished\" to see if the results \"fits\" the basic premise of \"Women and Children First\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT the number of males and females who SURVIVED (pandas series.)\n",
    "survived = 1\n",
    "s_males, s_females = males_vs_females(titanic_df, survived)\n",
    "print (\"Males: \", s_males, \"Females: \", s_females)\n",
    "\n",
    "# NOTICE: There were more than 2X females to males who survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH the number of males and females who SURVIVED\n",
    "\n",
    "objects = ('Males', 'Females')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [s_males, s_females]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.7)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Survivors')\n",
    "plt.title('Males vs Females Survivors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT the number of males and females who PERISHED (pandas series.)\n",
    "perished = 0\n",
    "p_males, p_females = males_vs_females(titanic_df, perished)\n",
    "print (\"Males: \", p_males, \"Females: \", p_females)\n",
    "\n",
    "# NOTICE: There were more than 5.5X the number of males that perished compared to females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH the number of males and females who PERISHED \n",
    "\n",
    "objects = ('Males', 'Females')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [p_males, p_females]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.7)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Perished')\n",
    "plt.title('Males vs Females Perished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  \n",
    "\n",
    "**Conclusions of First Line of Investigation: **  \n",
    "\n",
    "Interrogating the data has shown us:\n",
    "\n",
    "\n",
    "* There were more than **twice** as many females as males represented in those who **survived**. **[Females: 233, Males: 109]**\n",
    "* A \"rough estimate\" is that there were more than **five and a half** times as many males who **perished** than females. **[Males: 468 Females: 81]**\n",
    "\n",
    "Therefore **reasonable to suspect** that the cultural imperative (Chivalry) of the time period **contributed significantly** as a factor in the survival rates.\n",
    "\n",
    "\n",
    "**However** - Although \"Chivalry\" is a major contributing factor in the survival rates, it is **not** the only one. There are more, and those will be the focus of the **next line of inquiry**.\n",
    "\n",
    "\n",
    ">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Second Line of Inquiry: Social Class and Survival on the Titanic**\n",
    "\n",
    "\n",
    "Wayne Hall from the Department of Psychiatry and Behavioural Science, The University of Western Australia, Nedlands, W.A.\n",
    "6009, Australia writes about the relationship between ** Social Status and Survival Rates** in a research study which concluded:\n",
    "\n",
    "\n",
    "> Passengers’ chances of surviving the sinking of the S.S. Titanic were **related to\n",
    "their sex and their social class: females were more likely to survive than males,\n",
    "and the chances of survival declined with social class** as measured by the class\n",
    "in which the passenger travelled. The probable reasons for these differences in\n",
    "rates of survival are discussed, as are the reasons accepted, by the **Mersey\n",
    "Committee of Inquiry** into the sinking.\n",
    "\n",
    "\n",
    "* Source: http://api.rue89.nouvelobs.com/sites/news/files/assets/document/2012/04/hallssm2261986.pdf\n",
    "\n",
    ">  \n",
    "\n",
    "\n",
    "**Key Question: ** To what extend did social status (class) impact the survival rates?\n",
    "\n",
    ">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** REQUIREMENT: ** Two new Tools for efficient (a) **hypothesis testing**, and for (b) **measuring accuracy** of the heuristics implementing new theories.\n",
    "\n",
    ">  What is constructed below is a simple **(a) heuristic function** to predict the survival rate for a given hypothesis and a **(b) scoring function** to determine the accuracy of those predictions against the \"Survived\" column of the dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic Implementation for *FEMALE ONLY* contributions to survival rates.\n",
    "# This small function gets executed via a Pandas DF MAP function for fast vectorized\n",
    "# calculations so it doesn't have to do much more than a quick compate and return.\n",
    "# Returns 0 or 1 depending on if 'female' or not.\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import statsmodels.api as sm  \n",
    "    \n",
    "def female_only_heuristic(cell):\n",
    "    if cell == 'female':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "# SCORING ALGORITHM for measuring accuracy of various Heuristics against the SURVIVED Column in the DataFrame.\n",
    "# This ingests TWO separate Pandas \"Series\" and does a case by case comparison of the predicted vs actual to\n",
    "# derive an overall score, and remadial stats.\n",
    "# The tallys for correct, incorrect, index and accuracy are then returned.\n",
    "\n",
    "from __future__ import division\n",
    "    \n",
    "def score_heuristic(predicted, actual):\n",
    "    correct = (predicted == actual).sum()\n",
    "    incorrect = (predicted != actual).sum()\n",
    "    total = len(actual)\n",
    "    return correct, incorrect, total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use vector operations of Pandas DataFrame for fast mapping of simple heuristic fuction\n",
    "# Capture resulting Pandas Series for later interrogation.\n",
    "\n",
    "female_only_heuristic_predictions = titanic_df['Sex'].map(female_only_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the survival reate predictions of the given heuristic results against the \n",
    "# actual SURVIVED column of the dataframe.\n",
    "\n",
    "fo_correct, fo_incorrect, index, fo_accuracy = score_heuristic(female_only_heuristic_predictions, titanic_df['Survived'])\n",
    "print (\"Correct: \", fo_correct, \"Incorrect: \", fo_incorrect, \"Index: \", index, \"Accuracy: \", fo_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ANALYSIS** - the contribution of ONLY **gender = 'female'** as a predictor to the survival rate is **very significant** at 78.67 % accuracy.\n",
    "\n",
    "This is a good secondary check to the validity of our first line of inquiry.\n",
    "\n",
    "\n",
    "**Next**, the contributions for the **Social Status (or Class)** will be investigated re-using the above tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Heuristic Implementation for *SOCIAL STATUS ONLY* contributions to survival rates.\n",
    "# This small function gets executed via a Pandas DF MAP function for fast vectorized\n",
    "# calculations so it doesn't have to do much more than a quick compate and return.\n",
    "# Returns 0 or 1 depending on if 'pclass' eq 1 or 2.\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def class_only_heuristic(pclass):\n",
    "    if (pclass == 1) or (pclass ==2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use vector operations of Pandas DataFrame for fast mapping of simple heuristic fuction\n",
    "# Capture resulting Pandas Series for later interrogation.\n",
    "\n",
    "class_only_heuristic_predictions = titanic_df['Pclass'].map(class_only_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the survival reate predictions of the given heuristic results against the \n",
    "# actual SURVIVED column of the dataframe.\n",
    "\n",
    "co_correct, co_incorrect, index, co_accuracy = score_heuristic(class_only_heuristic_predictions, titanic_df['Survived'])\n",
    "print (\"Correct: \", co_correct, \"Incorrect: \", co_incorrect, \"Index: \", index, \"Accuracy: \", co_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ANALYSIS** - the contribution of Class ONLY **(Pclass = 1 or 2)** as a predictor to the survival rate is ** significant** at 66.77 % accuracy.\n",
    "\n",
    "This supports that argument that Social Status (as Pclass) is also significant contributor to survival rates.\n",
    "\n",
    "\n",
    ">  **Next**, the **isolation of contributing factors** can only be so helpful, the various factors **must be considered in combination** with each other for a composite score along with **\"other\"** contributing factors to establish more accurate predictive capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Heuristic Implementation for *COMBINATIONS* of contributions to survival rates.\n",
    "# Ingests a dataframe, constructs a predictions dictionary, and then populates it with \n",
    "# the survival predictions (both lived and perished) as calculated from the heuristic.\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import statsmodels.api as sm\n",
    "    \n",
    "def combination_heuristic(sex, pclass, age):\n",
    "    if ( (sex == 'female') or\n",
    "             (pclass == 1 and age <18 ) or\n",
    "             (pclass == 2 and age <18 ) or\n",
    "             (age < 1 and pclass == 3)\n",
    "            ):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use vector operations of Pandas DataFrame for fast mapping of simple heuristic fuction\n",
    "# Capture resulting Pandas Series for later interrogation. Since there are multiple columns \n",
    "# needing to be passed in, pass a lambda which unpacks the Series into separate arguments\n",
    "\n",
    "combination_heuristic_predictions = titanic_df[['Sex', 'Pclass', 'Age']].apply(lambda x: combination_heuristic(*x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the survival reate predictions of the given heuristic results against the \n",
    "# actual SURVIVED column of the dataframe.\n",
    "\n",
    "cmb_correct, cmb_incorrect, index, cmb_accuracy = score_heuristic(combination_heuristic_predictions, titanic_df['Survived'])\n",
    "print (\"Correct: \", cmb_correct, \"Incorrect: \", cmb_incorrect, \"Index: \", index, \"Accuracy: \", cmb_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ANALYSIS ** - Combinations of factors contributing to enhanced prediction accuracy. \n",
    "\n",
    "After lengthy contemplations and much experimentation with the combinations of factors, the following combination was arrived at which **achieved a level of predictive accuracy of 80% **.\n",
    "\n",
    "Each factor is given along with a commentary of why it might have contributed:\n",
    "\n",
    "* **Sex: Female** - this was the single most contributing factor toward survival. If one was female, they stood the best chance of survival.\n",
    "* **Pclass: 1 or 2 **- class was very significant in determining survival rates. The accuracy of the predictive powers of class were enhanced significantly when **Age** was combined. It seemed that **anyone under 18 who was in first or second class has a far better chance of survival**. \n",
    "* **Age and PClass** - Specifically **those under 1 years of age in 3rd class** stood a decent chance of survival. It would appear that the infants in 3rd class were given elevated priority. \n",
    "\n",
    ">   \n",
    "\n",
    "NOTE: **Some combinations had negative consequences** toward predictive accuracy, those were avoided.\n",
    "\n",
    ">  \n",
    "\n",
    "**Next** - Heuristics alone are **not sufficient** to uncover many of the **\"non-obvious\"** underlying combinations that are still significant contributors. In an attempt to find those we need to leverage a process from **Machine Learning** called **Feature Engineering**. To do this, we'll use a completely different dataframe (titanic_ml_df) on which to experiment on, leaving the original dataframe (titanic_df) in it's pure form. Any transformations of interest done on the \"titanic_ml_df\" will need to be manually injected into the \"titanic_df\" in the final heuristic.\n",
    "\n",
    ">  Note: Feature Engineering requires some **dataframe transformations** and the creation of some completely **new features**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MACHINE LEARNING DATAFRAME TRANSFORMATIONS**\n",
    "\n",
    "> The process of **feature engineering** requires transformations be done on existing columns in the dataframe. In the interest of maintaining purity of the original dataframes, it is recommended to use a completely different dataframe for this experimental process and then **inject the results back into the heuristic** construction. The necessary transformation are listed below:\n",
    "\n",
    "* **AGE** - Age has some missing values and/or NaN's which need to be addressed.\n",
    "* **SEX** - Sex has non-numeric values which need to be converted.\n",
    "* **EMBARKED** - Embarked also has non-numeric values which require conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data into a NEW dataframe for this process.\n",
    "filename = 'titanic_data.csv'\n",
    "titanic_ml_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine out the summary statistics of the dataframe for any obvious concerns\n",
    "titanic_ml_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data of dataframe for any obvious concerns\n",
    "\n",
    "titanic_ml_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATIONS / AREAS OF CONCERN**\n",
    "\n",
    "\n",
    "**AGE**\n",
    "\n",
    ">  The **AGE column** (above) the **count row** is **714** while the rest are 891. This indicates the presence of **missing values**, nulls, or NaN's.\n",
    "\n",
    "\n",
    "** SEX**\n",
    "\n",
    ">  The **SEX** Column needs to be transformed to a numeric field for Machine Learning Algorithms to operate on it.\n",
    "\n",
    "**EMBARKED**\n",
    "\n",
    ">  The **Embarked** column also needs to be transformed to a **dummy fields** for each port, and some NA's filled with 'S' so tha the Machine Learning Algorithms can operate on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MACHINE LEARNING DATAFRAME TRANSFORMATIONS CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MACHINE LEARNING DATAFRAME TRANSFORMATIONS\n",
    "\n",
    "# AGE - this column has missing values which we'll simply substitute the median values of the column for each one.\n",
    "titanic_ml_df[\"Age\"] = titanic_ml_df[\"Age\"].fillna(titanic_ml_df[\"Age\"].median())\n",
    "\n",
    "# SEX - transform from a string to numeric\n",
    "titanic_ml_df.loc[titanic_ml_df[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_ml_df.loc[titanic_ml_df[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "# EMBARKED - transform from a string to numeric\n",
    "titanic_ml_df[\"Embarked\"] = titanic_ml_df[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# NOTE: Categorical Variables \"Embarked\" cannot be represented as continuous:\n",
    "#       To fix this we create \"dummy\" variables where each category \n",
    "#       is given its own column and the values are 0 and 1 to indicate \n",
    "#       if the corresponding row is that category or not. Returns a dataframe.\n",
    "dummies = pd.get_dummies(titanic_ml_df['Embarked'])\n",
    "\n",
    "# Concatinate the \"dummies\" dataframe to the \"titanic_ml_df\" for further use.\n",
    "titanic_ml_df = pd.concat([titanic_ml_df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the Transformations worked as expected (NEW Columns C, Q, and S).\n",
    "titanic_ml_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GENERATING NEW FEATURES**\n",
    "\n",
    "There are some new features which could be generated that have the potential to add value to the accuracy of the predictive powers of the heuristic. The following are those:\n",
    "\n",
    "* **Length of the Name**  - could indicate how **wealthy** the person was and thus their **social standing** on the ship.\n",
    "* **Family Size** - defined as (SibSp + Parch),  larger or smaller families **might have preference**.\n",
    "* **Titles** - were generally an indication of **elevated social standing** such as: ( \"Major\", \"Col\", \"Mlle\" \"Don\", \"Lady\", \"Countess\", etc).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEW FEATURE GENERATION\n",
    "\n",
    "# FAMILY SIZE\n",
    "# Generating a NEW FamilySize column by adding the columns \"SibSp\" and \"Parch\"\n",
    "titanic_ml_df[\"FamilySize\"] = titanic_ml_df[\"SibSp\"] + titanic_ml_df[\"Parch\"]\n",
    "\n",
    "\n",
    "# NAME LENGTH :=> Leverage '.apply method'\n",
    "# Use the '.apply method' to generate a NEW column \"NameLength\" by taking the length of the NAME column\n",
    "#\n",
    "titanic_ml_df[\"NameLength\"] = titanic_ml_df[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "\n",
    "# TITLES\n",
    "# Extract the passengers TITLE from their name and create a NEW column \"TITLE\"\n",
    "\n",
    "# Function 'get-title' leveraging \"regular expressions\".\n",
    "# Returns the title or nothing if there is none.\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# :=> Leverage '.apply method' to fetch all of the titles from the NAME column\n",
    "titles = titanic_ml_df[\"Name\"].apply(get_title)\n",
    "\n",
    "\n",
    "# Create a numerical mapping for each extracted title of interest\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \n",
    "                 \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \n",
    "                 \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "\n",
    "# Create the Titles Series.\n",
    "for abreviation, value in title_mapping.items():\n",
    "    titles[titles == abreviation] = value\n",
    "\n",
    "# Add in the NEW Title column.\n",
    "titanic_ml_df[\"Title\"] = titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the New Features worked as expected. \n",
    "titanic_ml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FINDING THE BEST FEATURES**\n",
    "\n",
    ">  **Machine Learning** adds value to the quest to obtain more accuracy from our heuristic. One way to do this is to use the **univariate feature selection** from **Scikit-Learn**. This process (effectively) traverses each column and determines **which columns correlate most closely with what is attempting to predict** ['Survived']. **Scikit-Learn** has a function to make this process easier **SelectKBest**, which slects the best feature(s) from the data.\n",
    "\n",
    "\n",
    "**STATISTICAL RIGOR UNDER THE HOOD**\n",
    "\n",
    ">  The beauty of Scikit-Learn SelectKBest function is that it leverages all of the **important statistical tests** to ensure rigor in the determination process, specifically **ANOVA with F-values and P-values**.\n",
    "\n",
    "\n",
    "* Source: http://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html\n",
    "* Source: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "* Source: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINDING THE BEST FEATURE and PLOT them.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Establish Predictors\n",
    "# predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"C\", \"Q\", \"S\", \"FamilySize\", \"Title\"]\n",
    "\n",
    "# Perform feature selection using ANOVA F-value between labe/feature for classification tasks,\n",
    "# and get the appropriate features.\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic_ml_df[predictors], titanic_ml_df[\"Survived\"])\n",
    "\n",
    "# Fetch the raw p-values for each feature, and transform from p-values into scores\n",
    "# using Numpy's Log10 function.\n",
    "\n",
    "# NOTE: The \"-np.log10\" is used to ensure the normalization of the input variables (selector.pvalues_),\n",
    "#       that the input variables are approximately normal in distribution, and that the output variable \n",
    "#       is constant variance (that the variance of the output variable is independent of the input variables).\n",
    "#       Without this transformation the scores would not produce the results we desire (best feature).\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores, and NOTICE: the larger contribution of \"Pclass\", \"Sex\", \"Title\", and \"Fare\".\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('FEATURE CONTRIBUTIONS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALYSIS**\n",
    "\n",
    ">  Using Machine Learning techniques and leveraging its inherent statistical rigor, it was determined that the following features provided the most significant contributions to survival rate prediction:\n",
    "\n",
    "\n",
    "* \"Pclass\"\n",
    "* \"Sex\"\n",
    "* \"Title\"\n",
    "* \"Fare\"\n",
    "* \"C\" = Embarked at Cherbourg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Machine Learning for Scoring Thresholds**\n",
    "\n",
    "**WHY?** - Accuracy for Linear Regression techniques degrades if the data is non-linear in nature, which this dataset is. In order to achieve more accurate predictive capabilities, a non-linear approach is required, such as **Random Forests**.\n",
    "\n",
    ">  Machine Learning can provide enhanced accuracy levels for predictions. **Scikit-Learn** has a classifier called **\"RandomForestClassifier\"** which is more accurate. Using this to generate prediction accuracy levels establishes a threshold to aim for when it comes to improving the accuracy of the heuristics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHINE LEARNING -> RANDOM_FORREST_CLASSIFIER \n",
    "\n",
    "# Pick only the four best features - manually.\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\", \"C\"]\n",
    "\n",
    "# Use a forrest of 150 trees (avoid Over Fitting), split nodes at 8 samples, all nodes must have 4 leaves.\n",
    "algorithm = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "\n",
    "# Compute the accuracy score for all the forrests (cross validation folds)\n",
    "accuracy_scores = cross_validation.cross_val_score(algorithm, titanic_ml_df[predictors], titanic_ml_df[\"Survived\"], cv=3)\n",
    "\n",
    "# Take the mean of the scores\n",
    "print (\"RandomForestClassifier Accuracy: \" ,(accuracy_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MACHINE LEARNING ANALYSIS**\n",
    "\n",
    "> The **RandomForestClassifier** algorithm from the Scikit-Learn library is able to take the four best predictors **[\"Pclass\", \"Sex\", \"Fare\", \"Title\"]**, and generate a predictive measure of roughly **82.04** %. There is still room for improvement, but it does provide a reasonable goal to aim for from the heuristics, and a validation that they are performing well. The **next task** is to **inject the results of this experiment into the advanced heuristic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADVANCED HEURISTIC injected with Machine Learning Enhancements**\n",
    "\n",
    "**Injecting the Machine Learning Results into the Heuristic**\n",
    "\n",
    ">  The feature selection and accuracy thresholds from the Machine Learning process add value when injected into the hueristic. It's easier to see it in action when it's combined into an complete function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  ADVANCED HEURISTIC injected with Machine Learning Enhancements \n",
    "\n",
    "# Setup the various IMPORT statements for required libraries\n",
    "\n",
    "from IPython.display import Image\n",
    "import csv\n",
    "import re\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from __future__ import division  # forces \"/ \"to adopt Python 3.x's behavior that always returns a float.\n",
    "\n",
    "# Inline Graphics for IPython NB's\n",
    "# %pylab inline\n",
    "\n",
    "\n",
    "def advanced_heuristic(filename):   \n",
    "\n",
    "    # Containers to hold the heuristic contributions for plotting purposes.\n",
    "    #\n",
    "    contributions = {}   # Feature Contributions Dictionary\n",
    "                         # Individual Contribututors:\n",
    "    category_1 = 0       # Female \n",
    "    category_2 = 0       # 1stC <18\n",
    "    category_3 = 0       # 2ndC <18\n",
    "    category_4 = 0       # TC Infant\n",
    "    category_5 = 0       # Long Name (status)\n",
    "    category_6 = 0       # Title: Female Indicative\n",
    "    category_7 = 0       # Male under 15 of small familySize < 3\n",
    "    category_8 = 0       # Male, Title:(Master, Miss, Missis), 3rd Class, SibSp (number of siblings) <= 2\n",
    "    \n",
    "    # Create Predictions Dictionary & Read in the data into a DF\n",
    "    predictions = {}\n",
    "    titanic = pd.read_csv(filename)\n",
    "    \n",
    "    # FAMILY SIZE\n",
    "    # Generating a NEW FamilySize column by adding teh columns \"SibSp\" and \"Parch\"\n",
    "    titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "\n",
    "    # NAME LENGTH\n",
    "    # Use the '.apply method' to generate a NEW column \"NameLength\" by taking the length of the NAME column\n",
    "    titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "    # TITLES\n",
    "    # Extract the passengers TITLE from their name and create a NEW column \"TITLE\"\n",
    "\n",
    "    # Function 'get-title'\n",
    "    # Returns the title or nothing if there is none.\n",
    "    def get_title(name):\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "\n",
    "    # Use the '.apply method' to fetch all of the titles from the NAME column\n",
    "    titles = titanic[\"Name\"].apply(get_title)\n",
    "\n",
    "    # Create a numerical mapping for each extracted title of interest\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \n",
    "                     \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \n",
    "                     \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "\n",
    "    # Create the Titles Series.\n",
    "    for abreviation, value in title_mapping.items():\n",
    "        titles[titles == abreviation] = value\n",
    "\n",
    "    # Add in the NEW Title column.\n",
    "    titanic[\"Title\"] = titles      \n",
    "    \n",
    "    \n",
    "    # Heuristic Implementation \n",
    "    # Function applied as a vector operation of a Pandas Dataframe for fast execution.\n",
    "    # Ingests multiple Pandas Series and does a quick comparison returning a prediction of \n",
    "    # 0 or 1.\n",
    "    #\n",
    "    def heuristic(sex, pclass, age, namelength, title, familysize, sibsp):\n",
    "        if ( \n",
    "             (sex == 'female')                   # Female\n",
    "              or (pclass == 1 and age <19)       # 1stC <18\n",
    "              or (pclass == 2 and age <18)       # 2ndC <18\n",
    "              or (age < 1 and pclass == 3)       # TC Infant\n",
    "              or (namelength > 40)               # Long Name (status)\n",
    "              or (title == 2 or title == 8)      # Title: Female Indicative\n",
    "              or (sex == 'male' and age < 15 and familysize <3 ) # Male under 15 of small familySize < 3\n",
    "              # Male, Title:(master, Miss, Missis), 3rd Class, SibSp (number of siblings) <= 2\n",
    "              or (sex == 'male' and (title == 4 or title == 2) and pclass == 3 and sibsp <= 2)            \n",
    "            ):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0      \n",
    "    \n",
    "\n",
    "    # Use vector operations of Pandas DataFrame for fast mapping of simple heuristic fuction\n",
    "    # Capture resulting Pandas Series for later interrogation. Since there are multiple columns \n",
    "    # needing to be passed in, pass a lambda which unpacks the Series into separate arguments    \n",
    "    predictions = titanic[['Sex', 'Pclass', 'Age', 'NameLength', 'Title', 'FamilySize', 'SibSp']].apply(lambda x: heuristic(*x), axis=1)\n",
    "       \n",
    "    \n",
    "    # Gather Simple Statistical Contribution Data for plots.\n",
    "    #\n",
    "    for passenger_index, passenger in titanic.iterrows():\n",
    "        # Capture simple Contrbution Data for PLOTTING purposes.\n",
    "        if passenger['Sex'] == 'female':\n",
    "            category_1 +=1\n",
    "        if (passenger['Pclass'] == 1 and passenger['Age'] <19):\n",
    "            category_2 +=1\n",
    "        if (passenger['Pclass'] == 2 and passenger['Age'] <18):\n",
    "            category_3 +=1\n",
    "        if (passenger['Age'] < 1 and passenger['Pclass'] == 3):\n",
    "            category_4 +=1\n",
    "        if (passenger['NameLength'] > 40):\n",
    "            category_5 +=1\n",
    "        if (passenger[\"Title\"] == 2 or passenger[\"Title\"] == 8):\n",
    "            category_6 +=1\n",
    "        if (passenger['Sex'] == 'male' and passenger['Age'] < 15 and passenger['FamilySize'] <3 ):\n",
    "            category_7 +=1\n",
    "        if (passenger['Sex'] == 'male' and (passenger[\"Title\"] == 4 or passenger[\"Title\"] == 2) \n",
    "                                       and passenger['Pclass'] == 3 and passenger['SibSp'] <= 2):\n",
    "            category_8 +=1        \n",
    "        \n",
    "    # Append contributions to a dictionary:    \n",
    "    contributions.update({'category_1': category_1, 'category_2': category_2, 'category_3': category_3, \n",
    "                          'category_4': category_4, 'category_5': category_5, 'category_6': category_6,\n",
    "                          'category_7': category_7, 'category_8': category_8,})          \n",
    "\n",
    "        \n",
    "    return predictions, contributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the survival rate predictions for the ADVANCED HEURISTIC\n",
    "\n",
    "advanced_heuristic_predictions, advanced_heuristic_contributions = advanced_heuristic(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the survival reate predictions of the given heuristic results against the \n",
    "# actual SURVIVED column of the dataframe.\n",
    "\n",
    "adv_correct, adv_incorrect, index, adv_accuracy = score_heuristic(advanced_heuristic_predictions, titanic_df['Survived'])\n",
    "print (\"Correct: \", adv_correct, \"Incorrect: \", adv_incorrect, \"Index: \", index, \"Accuracy: \", adv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALYSIS**\n",
    "\n",
    "**Commentary on combinations of features contributing to enhanced accuracy **\n",
    "\n",
    "After lengthy contemplations and much experimentation with the combinations of factors, the following combination(s) were arrived at which achieved a level of predictive accuracy greater than **81 % ** .\n",
    "\n",
    "Each factor is given along with a commentary of why it might have contributed:\n",
    "\n",
    ">   **TITLE** - Female indicative: (\"Miss\", \"Ms\", \"Mlle\", \"Mme\"). Any indication a person was a **female** enhanced the survival rate. \n",
    "\n",
    ">   **MALES** - (under 15 of families < 3). Males under 15 and of small families (probably the only child to carry on the family name) improved the odds of survival.\n",
    "\n",
    ">   **UNIQUE COMBINATION** - Male, Title:(\"Master\", \"Miss\", \"Ms\"), 3rd Class, SibSp (number of siblings) <= 2. Some unique combinations did indeed contribute, but these were hardly intuitive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PIE CHART - Breakdown of Feature Contributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIE CHART - Breakdown of Feature Contributions\n",
    "\n",
    "# category_1       # Female \n",
    "# category_2       # 1stC < 18\n",
    "# category_3       # 2ndC < 18\n",
    "# category_4       # 3rdC Infant\n",
    "# category_5       # Long Name (status)\n",
    "# category_6       # Title: Female Indicative\n",
    "# category_7       # Male under 15 of small familySize < 3\n",
    "# category_8       # Male, Title:(master, Miss, Missis), 3rd Class, SibSp (number of siblings) <= 2\n",
    "\n",
    "\n",
    "category_1 = advanced_heuristic_contributions['category_1']\n",
    "category_2 = advanced_heuristic_contributions['category_2']\n",
    "category_3 = advanced_heuristic_contributions['category_3']\n",
    "category_4 = advanced_heuristic_contributions['category_4']\n",
    "category_5 = advanced_heuristic_contributions['category_5']\n",
    "category_6 = advanced_heuristic_contributions['category_6']\n",
    "category_7 = advanced_heuristic_contributions['category_7']\n",
    "category_8 = advanced_heuristic_contributions['category_8']\n",
    "\n",
    "# GRAPH - Feature Contributions\n",
    "labels = 'Female', '1stC < 18', '2ndC < 18', '3rdC Infant', 'Long Name (status)', 'Title: Female Indicative', 'Male < 15, FamSiz < 3', 'Unique Combo'\n",
    "contributions = [category_1, category_2, category_3, category_4, category_5, category_6, category_7, category_8]\n",
    "colors = ['red', 'blue', 'green', 'purple', 'yellow', 'green', 'brown', 'black' ]\n",
    "explode = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)  # explode each slice\n",
    "\n",
    "plt.pie(contributions, explode=explode, labels=labels, colors=colors, autopct='%1.3f%%', shadow=True, startangle=45)\n",
    "plt.axis('equal')\n",
    "plt.title('Feature Contributions')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** BAR CHART - Breakdown of Feature Contributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAR CHART - Breakdown of Feature Contributions\n",
    "objects = ('Female', '1stC < 18', '2ndC < 18', '3rdC Infant', 'Long Name (status)', 'Title: Female Indicative', 'Male < 15, FamSiz < 3', 'Unique Combo')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [category_1, category_2, category_3, category_4, category_5, category_6, category_7, category_8]\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Contributions')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Contributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FINDINGS & CONCLUSIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **KEY QUESTION: \"What factors made people more likely to survive?\"**\n",
    "\n",
    ">  \n",
    "\n",
    "**(1) Initial Line of Inquiry:**\n",
    "\n",
    ">  Did the **\"Chivalry\"** and the **\"Women and Children First\"** cultural imperative of the time period manifest itself in the data as it would be expected to?\n",
    "\n",
    "**ANALYSIS** - Interrogating the data has shown us:\n",
    "\n",
    "* There were more than **twice** as many females as males represented in those who **survived**. **[Males: 109 Females: 233]**\n",
    "* There were more that **five and a half** times as many males who **perished** than females. **[Males: 468 Females: 81]**\n",
    "\n",
    "Therefore **reasonable to infer ** that the cultural imperative (Chivalry) of the time period **contributed significantly** as a factor in the survival rates at **78.67 %** accuracy.\n",
    "\n",
    ">  \n",
    "\n",
    "**(2) Second Line of Inquiry:**\n",
    "\n",
    ">  Were the passengers chances of surviving the disaster related to their **gender and their social class**  as measured by the class in which the passenger traveled.  \n",
    "\n",
    "**ANALYSIS** - the contribution of Class ONLY **(Pclass = 1 or 2)** as an independent predictor to the survival rate is **significant** at **66.77 %** accuracy, which supports the argument that **social status played a significant role** in survival rates.\n",
    "\n",
    "\n",
    ">  \n",
    "\n",
    "\n",
    "**(3) Third Line of Inquiry:**\n",
    "\n",
    ">   Were there unique (and occasionally non-intuitive) **combinations of features** contributing to survival rates?\n",
    "\n",
    "\n",
    "**ANALYSIS** - The consideration of contributing factors in **isolation** is **not** sufficient to achieve more accurate prediction / understanding of survival rates, those factors need to be **considered in concert** with each other to better understand the total picture. \n",
    "\n",
    "The following contributing factors were **considered in concert** with each achieving a level of predictive accuracy at the ** 80 % ** range:\n",
    "\n",
    "* **Sex: Female** - this was the single most contributing factor toward survival. If one was female, they stood the best chance of survival.\n",
    "* **Pclass: 1 or 2 **- class was very significant in determining survival rates. The accuracy of the predictive powers of class were enhanced significantly when **Age** was combined. It seemed that **anyone under 18 who was in first or second class has a far better chance of survival**. \n",
    "* **Age and PClass** - Specifically **those under 1 years of age in 3rd class** stood a decent chance of survival. It would appear that the infants in 3rd class were given elevated priority. \n",
    "\n",
    ">  \n",
    "  \n",
    "\n",
    "**(4) Forth Line of Inquiry:**\n",
    "\n",
    ">  Are there contributions from **Machine Learning** which could improve predictive accuracy? What is the net result of those contributions?\n",
    "\n",
    "**ANALYSIS** - Machine Learning Algorithms are able to discern (unique) combinations of features in concert with each other that provide more accurate predictions. The two aspects chosen to assist in this study were: \n",
    "\n",
    "* **(A) Feature Engineering** - The **univariate feature selection** from **Scikit-Learn** using the **SelectKBest**, slects the **best feature(s)** from the data, and given this dataset recommended the features: **[\"Pclass\", \"Sex\", \"Fare\", \"Title\"]** as contributing the most to predictive accuracy.\n",
    "\n",
    "\n",
    "* **(B) Machine Learning Accuracy Enhancements** - The **RandomForestClassifier** algorithm from the **Scikit-Learn** library is able to take the four best predictors **[\"Pclass\", \"Sex\", \"Fare\", \"Title\"]**, and generate a predictive measure in excess of **81.2 %**. There is still room for improvement, but it does provide a reasonable goal to aim for from the heuristics, and a validation that they are performing well.\n",
    "\n",
    ">  \n",
    "\n",
    "** Fifth Line of Inquiry:**\n",
    "\n",
    ">  Will injecting Machine Learning enhancements into the heuristic improve accuracy?\n",
    "\n",
    "**ANALYSIS** - Upon injecting the products of the Machine Learning Experiment into the Heuristic the following combination(s) were arrived at which achieved a level of predictive accuracy slightly greater than **81 % **. Those **injected features** were:\n",
    "\n",
    ">   **TITLE** - Female indicative: (\"Miss\", \"Ms\", \"Mlle\", \"Mme\"). Any indication a person was a female aided in the survival rate. \n",
    "\n",
    ">   **MALES** - (under 15 of families < 3). Males uder 15 and of small families (probably the only child to carry on the family name) improved the odds of survival.\n",
    "\n",
    ">   **UNIQUE COMBINATION** - Male, Title:(\"Master\", \"Miss\", \"Ms\"), 3rd Class, SibSp (number of siblings) <= 2. Some unique combinations did indeed proved significant, but hardly intuitive.\n",
    "\n",
    ">  \n",
    "\n",
    "** CONCLUSION: Feature Composition of the Advanced Heuristic**\n",
    "\n",
    "> The following is the final composition of features comprising the Advanced Heuristic and an answer to the question of **\"What factors made people more likely to survive\".** \n",
    "\n",
    "**Those factors were:**\n",
    "\n",
    "* Female Gender\n",
    "* 1st Class Passenger under the age of 18\n",
    "* 2nd Class Passenger under the age of 18\n",
    "* Third Class Infant of one year or younger.\n",
    "* Long Name (As Indicator of Social Status and therefore Travel Class.)\n",
    "* Title: Anything Female Indicative (Miss, Mrs, etc ....)\n",
    "* Male under 15 of small familySize < 3 - Probably the only Male to continue the family name.\n",
    "* Unique (non intuitive) Combination: Male, Title:(Master, Miss, Missis), 3rd Class, SibSp (number of siblings) <= 2\n",
    "    \n",
    "\n",
    ">  \n",
    ">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** LIMITATIONS AND SHORTCOMINGS **\n",
    "\n",
    "> Some of the most obvious limitations are:\n",
    "* Small and incomplete data set\n",
    "* Relative unsophisticated heuristics algorithm\n",
    "* Lack of Dominant features for the last 20% of accuracy\n",
    "* Machine Learning Sophistication (Decision Trees)\n",
    "\n",
    "> The **small and incomplete data set**  is really the biggest limitation of this study. It's difficult to ferret out all of the features possible in route to developing a more accurate heuristic when the data is not a rich as it could be. This contributes to a **relatively unsophisticated heuristics algorithm**. Although the heuritsics algorithm is a product of intitution and an injection of Machine Leanning discoveries (feature engineering), it could be better, particularly in the last 15 - 18% accuracy (post 81%). Since there is a **lack of a dominant feature for that last percentage of accuracy**, it's difficult to make progress past 81% or so. Finally, the promise of accuracy advancements from **Machine Learning Decision Trees** was not taken as far as possible and could be improved.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFERENCES**\n",
    "\n",
    "\n",
    "Event Background:\n",
    "https://en.wikipedia.org/wiki/RMS_Titanic\n",
    "\n",
    "Passengers Information:\n",
    "https://en.wikipedia.org/wiki/Passengers_of_the_RMS_Titanic\n",
    "\n",
    "1912 chivalry vs 2012 Cowardice:\n",
    "http://www.reddirtreport.com/dust-devil-dreams/1912-chivalry-vs-2012-cowardice\n",
    "\n",
    "The Costa Concordia, The Titanic, and Cowardice at Sea:\n",
    "http://blogs.wsj.com/speakeasy/2012/01/23/the-costa-concordia-the-titanic-and-cowardice-at-sea/\n",
    "\n",
    "Social Class and Survival on the Titanic:\n",
    "http://api.rue89.nouvelobs.com/sites/news/files/assets/document/2012/04/hallssm2261986.pdf\n",
    "\n",
    "Titanic: Machine Learning from Disaster:\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "Data Repository:\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "Part One:\n",
    "https://www.dataquest.io/mission/74/getting-started-with-kaggle\n",
    "\n",
    "Part Two:\n",
    "https://www.dataquest.io/mission/75/improving-your-submission\n",
    "\n",
    "Titanic's Band:\n",
    "https://en.wikipedia.org/wiki/Legends_and_myths_regarding_RMS_Titanic\n",
    "\n",
    "Sicikit-Learn:\n",
    "http://scikit-learn.org/stable/\n",
    "\n",
    "Univariate Feature Selection:\n",
    "http://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html\n",
    "\n",
    "SelectKBest:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "\n",
    "RandomForestClassifier:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "MatPlotLib:\n",
    "https://pythonspot.com/matplotlib-bar-chart/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
